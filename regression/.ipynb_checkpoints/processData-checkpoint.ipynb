{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import subprocess\n",
    "\n",
    "#Params\n",
    "datasetPath = \"../datasets/\"\n",
    "dataPath = \"./data/\"\n",
    "resultPath = \"./results/\"\n",
    "filenames = [\"Apache\",\"BerkeleyC\",\"BerkeleyJ\",\"Dune\",\"HIPAcc\",\"HSMGP\",\"JavaGC\",\"LLVM\",\"SQLite\"]\n",
    "filenames = [\"Apache\"]\n",
    "perf=\"perf\"\n",
    "\n",
    "\n",
    "#Params for sensistivity\n",
    "NBINS = 40 # Number of vertical bins for threshold\n",
    "NSUBS = 10 # Number of training sets to average on\n",
    "srm = 1 # Minimum sampling size\n",
    "srM=[]\n",
    "srs = []\n",
    "for k,filename in enumerate(filenames):\n",
    "    srM.append(int(subprocess.check_output(\"echo $(wc -l < \"+datasetPath+filename+\".csv)\", shell=True))) # Maximum sampling size\n",
    "    srs.append(srM[k]//100) # Sampling step between two iterations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sys, os\n",
    "import pandas as pd\n",
    "from sklearn import tree\n",
    "import numpy as np\n",
    "\n",
    "def sensitivityRegression(datasetPath, dataPath, filename, perf, NBINS, NSUBS, srm, srM, srs, thresholds=False):\n",
    "    \n",
    "    #If data fodler does not exists\n",
    "    if not os.path.exists(dataPath):\n",
    "        try:\n",
    "            os.makedirs(dataPath)\n",
    "        except OSError as exc: # Guard against race condition\n",
    "            if exc.errno != errno.EEXIST:\n",
    "                raise\n",
    "            \n",
    "    perf_x264 = ['Watt', 'Energy', 'SSIM', 'PSNR', 'Speed', 'Size', 'Time']\n",
    "    perf_sac = ['compile-exit', 'compile-real', 'compile-user', 'compile-ioin', 'compile-ioout',\n",
    "                'compile-maxmem', 'compile-cpu', 'compile-size', 'run-exit',\n",
    "                'run-real', 'run-user', 'run-maxmem', 'run-cpu']\n",
    "\n",
    "    d = pd.read_csv(datasetPath+filename+\".csv\") # Open dataset\n",
    "    d = d.sort_values(by=perf) # Sort it by perf to get threshold values\n",
    "    if not thresholds:\n",
    "        thresholds = [d[perf].iloc[i * d.shape[0]//NBINS] for i in range(1, NBINS)]\n",
    "    else:\n",
    "        thresholds = [d[perf].iloc[int(thresholds * d.shape[0])]]\n",
    "\n",
    "    res = {\"sr\":[],\"t\":[],\"TN\":[],\"TP\":[],\"FN\":[],\"FP\":[]}\n",
    "\n",
    "    # Computation\n",
    "    for sr in range(srm,srM,srs):\n",
    "        for t in thresholds:\n",
    "            print(\"Computing for sr=%d and t=%.3f...\" % (sr, t))\n",
    "            d[\"label\"] = 0\n",
    "            d.loc[d[perf] > t, \"label\"] = 1 # Label with the (current) oracle\n",
    "            clean = d.drop(perf_sac+perf_x264,axis=1,errors=\"ignore\")\n",
    "            subs = [clean.sample(sr) for i in range(NSUBS)] # Subsample trainsets\n",
    "            TN = TP = FN = FP = 0 # Counters for classification results\n",
    "            d[\"pred\"] = 0\n",
    "            d[\"labelpred\"] = 0\n",
    "            for s in subs: # We cumulate results for each experiment and average later\n",
    "                # MACHINE LEARNING PART\n",
    "                # Settings are chosen to be the closest to J48 algorithm\n",
    "                c = tree.DecisionTreeRegressor(min_samples_leaf=2)\n",
    "                c.fit(s.drop([\"perf\",\"label\"],axis=1), s.perf)\n",
    "                # END OF LEARNING\n",
    "                d[\"pred\"] = c.predict(clean.drop([\"perf\",\"label\"], axis=1)) # Get model's prediction\n",
    "                d.loc[d[\"pred\"] > t, \"labelpred\"] = 1 # Label with the (current) oracle\n",
    "                TN += d[(d.label == 0) & (d.labelpred == 0)].shape[0]\n",
    "                TP += d[(d.label == 1) & (d.labelpred == 1)].shape[0]\n",
    "                FN += d[(d.label == 1) & (d.labelpred == 0)].shape[0]\n",
    "                FP += d[(d.label == 0) & (d.labelpred == 1)].shape[0]\n",
    "            del d[\"pred\"] # Reset\n",
    "            del d[\"labelpred\"] # Reset\n",
    "            # Push the results\n",
    "            res[\"sr\"].append(sr)\n",
    "            res[\"t\"].append(t)\n",
    "            res[\"TN\"].append(TN/NSUBS)\n",
    "            res[\"TP\"].append(TP/NSUBS)\n",
    "            res[\"FN\"].append(FN/NSUBS)\n",
    "            res[\"FP\"].append(FP/NSUBS)\n",
    "    # Save the result as csv\n",
    "    pd.DataFrame(res).to_csv(dataPath+filename+\"-regression.csv\", index=False)\n",
    "\n",
    "\n",
    "def sensitivityClassification(datasetPath, dataPath, filename, perf, NBINS, NSUBS, srm, srM, srs, thresholds=False):\n",
    "    \n",
    "    #If data fodler does not exists\n",
    "    if not os.path.exists(dataPath):\n",
    "        try:\n",
    "            os.makedirs(dataPath)\n",
    "        except OSError as exc: # Guard against race condition\n",
    "            if exc.errno != errno.EEXIST:\n",
    "                raise\n",
    "            \n",
    "    perf_x264 = ['Watt', 'Energy', 'SSIM', 'PSNR', 'Speed', 'Size', 'Time']\n",
    "    perf_sac = ['compile-exit', 'compile-real', 'compile-user', 'compile-ioin', 'compile-ioout',\n",
    "                'compile-maxmem', 'compile-cpu', 'compile-size', 'run-exit',\n",
    "                'run-real', 'run-user', 'run-maxmem', 'run-cpu']\n",
    "\n",
    "    d = pd.read_csv(datasetPath+filename+\".csv\") # Open dataset\n",
    "    d = d.sort_values(by=perf) # Sort it by perf to get threshold values\n",
    "    if not thresholds:\n",
    "        thresholds = [d[perf].iloc[i * d.shape[0]//NBINS] for i in range(1, NBINS)]\n",
    "    else:\n",
    "        thresholds = [d[perf].iloc[int(thresholds * d.shape[0])]]\n",
    "\n",
    "    res = {\"sr\":[],\"t\":[],\"TN\":[],\"TP\":[],\"FN\":[],\"FP\":[]}\n",
    "\n",
    "    # Computation\n",
    "    for sr in range(srm,srM,srs):\n",
    "        for t in thresholds:\n",
    "            print(\"Computing for sr=%d and t=%.3f...\" % (sr, t))\n",
    "            d[\"label\"] = 0\n",
    "            d.loc[d[perf] > t, \"label\"] = 1 # Label with the (current) oracle\n",
    "            clean = d.drop(perf_sac+perf_x264+[\"perf\"],axis=1,errors=\"ignore\")\n",
    "            subs = [clean.sample(sr) for i in range(NSUBS)] # Subsample trainsets\n",
    "            TN = TP = FN = FP = 0 # Counters for classification results\n",
    "            d[\"pred\"] = 0\n",
    "            for s in subs: # We cumulate results for each experiment and average later\n",
    "                # MACHINE LEARNING PART\n",
    "                # Settings are chosen to be the closest to J48 algorithm\n",
    "                c = tree.DecisionTreeClassifier(criterion=\"entropy\", min_samples_leaf=2)\n",
    "                c.fit(s.drop([\"label\"],axis=1), s.label)\n",
    "                # END OF LEARNING\n",
    "                d[\"pred\"] = c.predict(clean.drop([\"label\"], axis=1)) # Get model's prediction\n",
    "                TN += d[(d.label == 0) & (d.pred == 0)].shape[0]\n",
    "                TP += d[(d.label == 1) & (d.pred == 1)].shape[0]\n",
    "                FN += d[(d.label == 1) & (d.pred == 0)].shape[0]\n",
    "                FP += d[(d.label == 0) & (d.pred == 1)].shape[0]\n",
    "            del d[\"pred\"] # Reset\n",
    "            # Push the results\n",
    "            res[\"sr\"].append(sr)\n",
    "            res[\"t\"].append(t)\n",
    "            res[\"TN\"].append(TN/NSUBS)\n",
    "            res[\"TP\"].append(TP/NSUBS)\n",
    "            res[\"FN\"].append(FN/NSUBS)\n",
    "            res[\"FP\"].append(FP/NSUBS)\n",
    "    # Save the result as csv\n",
    "    pd.DataFrame(res).to_csv(dataPath+filename+\"-classification.csv\", index=False)\n",
    "    \n",
    "def sensitivity(datasetPath, dataPath, filename, perf, NBINS, NSUBS, srm, srM, srs, thresholds=False):\n",
    "    sensitivityClassification(datasetPath = datasetPath, dataPath = dataPath, filename = filename,\n",
    "                perf = perf, NBINS = NBINS, NSUBS = NSUBS, srm = srm, srM = srM, srs = srs)\n",
    "    sensitivityRegression(datasetPath = datasetPath, dataPath = dataPath, filename = filename,\n",
    "                perf = perf, NBINS = NBINS, NSUBS = NSUBS, srm = srm, srM = srM, srs = srs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k,filename in enumerate(filenames):\n",
    "    #Machine learning part, using data from {filename} file in {datasetPath} folder and writing results in {dataPath} folder\n",
    "    sensitivity(datasetPath = datasetPath, dataPath = dataPath, filename = filename,\n",
    "                perf = perf, NBINS = NBINS, NSUBS = NSUBS, srm = srm, srM = srM[k], srs = srs[k])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#If results folder does not exist\n",
    "if not os.path.exists(resultPath):\n",
    "    try:\n",
    "        os.makedirs(resultPath)\n",
    "    except OSError as exc: # Guard against race condition\n",
    "        if exc.errno != errno.EEXIST:\n",
    "            raise\n",
    "\n",
    "#For each file, get the min and max values to have a global colorscale and then use the R script to create the heatmaps\n",
    "for filename in filenames:\n",
    "    metrics = [\"accuracy\",\"specificity\",\"precision\",\"recall\",\"npv\",\"negNPV\",\"negAccuracy\"]\n",
    "    minArray={}\n",
    "    maxArray={}\n",
    "    for m in metrics:\n",
    "        minArray[m] = 1\n",
    "        maxArray[m] = -1\n",
    "\n",
    "\n",
    "    for file in [filename+\"-classification.csv\",filename+\"-regression.csv\"]:\n",
    "        df = pd.read_csv(dataPath+file)\n",
    "\n",
    "        df['accuracy']= (df['TP']+df['TN']) / (df['TP']+df['TN']+df['FN']+df['FP'])\n",
    "        df['specificity']=df['TN']/(df['TN']+df['FP'])\n",
    "        df['precision']=df['TP']/(df['TP'] + df['FP'])\n",
    "        df['recall']= df['TP'] / (df['TP']+ df['FN']) # Recall of class 1\n",
    "        df['npv']=df['TN']/(df['TN']+df['FN'])\n",
    "\n",
    "        df['index']=df.groupby('sr').cumcount()+1\n",
    "        df['frequency']=max(df['index'])\n",
    "        df['index']= df['index'] * 100 / df['frequency']\n",
    "\n",
    "        df['negNPV']=df['npv']-(df['index']/100)\n",
    "        df['negAccuracy']=df['accuracy']-(df['index']/100)\n",
    "\n",
    "        for m in metrics:\n",
    "            if max(df[m])>maxArray[m] and not np.isnan(max(df[m])):\n",
    "                maxArray[m] = max(df[m])\n",
    "            elif np.isnan(max(df[m])):\n",
    "                if np.nanmax(df[m].values)>maxArray[m]:\n",
    "                    maxArray[m] = np.nanmax(df[m].values)\n",
    "            if min(df[m])<minArray[m] and not np.isnan(min(df[m])):\n",
    "                minArray[m] = min(df[m])\n",
    "            elif np.isnan(min(df[m])):\n",
    "                if np.nanmin(df[m].values)<minArray[m]:\n",
    "                    minArray[m] = np.nanmin(df[m].values)\n",
    "\n",
    "\n",
    "    minmax = pd.DataFrame([minArray,maxArray])\n",
    "    minmax.to_csv(dataPath+\"minmax-\"+filename+\".csv\", index=False)\n",
    "    \n",
    "    !Rscript ./helpers/2.calculateMetrics.R {dataPath}{filename} {resultPath} {dataPath}\"minmax-\"{filename}\".csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
